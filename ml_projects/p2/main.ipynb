{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('learning_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "59b79390f4c38bdb7f9a1cc0126cfae8736f4189a43e4520a1eb5348844dd53e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.84      0.80      0.82        20\ncomp.sys.ibm.pc.hardware       0.78      0.90      0.84        20\n   talk.politics.mideast       0.90      0.95      0.93        20\n               sci.crypt       0.95      0.95      0.95        20\n      talk.politics.misc       0.80      0.60      0.69        20\n               rec.autos       1.00      0.80      0.89        20\n      rec.sport.baseball       1.00      1.00      1.00        20\n                 sci.med       0.86      0.95      0.90        20\n         rec.motorcycles       0.87      1.00      0.93        20\n   comp.sys.mac.hardware       0.91      1.00      0.95        20\n  soc.religion.christian       1.00      1.00      1.00        20\n         sci.electronics       0.94      0.80      0.86        20\n comp.os.ms-windows.misc       0.86      0.95      0.90        20\n            misc.forsale       0.91      1.00      0.95        20\n          comp.windows.x       1.00      0.80      0.89        20\n        rec.sport.hockey       1.00      1.00      1.00        20\n               sci.space       0.95      0.90      0.92        20\n           comp.graphics       0.95      0.90      0.92        20\n      talk.religion.misc       0.64      0.70      0.67        20\n      talk.politics.guns       0.77      0.85      0.81        20\n\n                accuracy                           0.89       400\n               macro avg       0.90      0.89      0.89       400\n            weighted avg       0.90      0.89      0.89       400\n\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data_raw = Path('mini_newsgroups')\n",
    "tag_raw = list(data_raw.glob('*/*'))\n",
    "tag_raw = [str(name) for name in tag_raw]\n",
    "\n",
    "def path2news(path):\n",
    "    path_list = path.split('/')\n",
    "    return path_list[1]\n",
    "\n",
    "news_labels = list(map(lambda x: path2news(x), tag_raw))\n",
    "\n",
    "news_to_index = dict((name, index) for index, name in enumerate(list(set(news_labels))))\n",
    "\n",
    "news_targets = [news_to_index[name] for name in news_labels]\n",
    "\n",
    "# # 取文件夹的名字作为标签\n",
    "# tag = []\n",
    "# i = 0\n",
    "# while i < len(tag_raw) :\n",
    "#     name = tag_raw[i].split('/')\n",
    "#     tag.append(name[1])\n",
    "#     i+=100\n",
    "\n",
    "# # 给tag打上数字标签\n",
    "# tag_to_index = dict((name,index) for index, name in enumerate(tag))\n",
    "\n",
    "# news_targets = [tag_to_index[name] for name in news_labels]\n",
    "\n",
    "# 对新闻数据进行处理\n",
    "def newsSolve(path_news):\n",
    "    file_raw = open(path_news, 'r', encoding='ISO-8859-1')\n",
    "    \n",
    "    content_raw = file_raw.read()\n",
    "\n",
    "    # 去除换行\n",
    "    content_raw = re.sub('\\n', ' ', content_raw)\n",
    "    content_raw = re.sub('\\d+', ' ', content_raw)\n",
    "\n",
    "    # 去除常见字符\n",
    "    chars_common = \"[\\!\\:\\<\\>\\...\\-\\'\\)\\(\\/_,$%^*(+\\\"\\']+|[+——! ，：。；、~@#¥%……&*（）]+\"\n",
    "    content_raw = re.sub(chars_common, ' ', content_raw)\n",
    "\n",
    "    # 首先进行分句\n",
    "    sentence_content_raw = nltk.sent_tokenize(content_raw)\n",
    "\n",
    "    # 再对每句进行分词\n",
    "    word = []\n",
    "    for sentence in sentence_content_raw :\n",
    "        word_list = nltk.word_tokenize(sentence)\n",
    "        word.extend(word_list)\n",
    "\n",
    "    return word\n",
    "\n",
    "news_split = list(map(lambda x: newsSolve(x), tag_raw))\n",
    "\n",
    "stop_words = list(ENGLISH_STOP_WORDS)\n",
    "for x in list(nltk.corpus.stopwords.words('english')):\n",
    "    if x not in stop_words:\n",
    "        stop_words.append(x)\n",
    "\n",
    "news_split_2 = []\n",
    "for words in news_split:\n",
    "    cur_words = list(map(lambda x: x if x not in stop_words else \"\", words))\n",
    "    news_split_2.append(\" \".join(cur_words))\n",
    "\n",
    "# 五重交叉\n",
    "news_fivecross = []\n",
    "tar_fivecross = []\n",
    "for i in range(5):\n",
    "    for j in range(20):\n",
    "        for k in range(i * 20 + j * 100, (i + 1) * 20 + j * 100):\n",
    "            news_fivecross.append(news_split_2[k])\n",
    "            tar_fivecross.append(news_targets[k])\n",
    "\n",
    "news_fivecross.extend(news_fivecross)\n",
    "tar_fivecross.extend(tar_fivecross)\n",
    "\n",
    "res_fivecross = []\n",
    "for i in range(5):\n",
    "    vector = TfidfVectorizer(stop_words=stop_words, decode_error='ignore')\n",
    "\n",
    "    x_test = news_fivecross[i * 400: i * 400 + 400]\n",
    "    y_test = tar_fivecross[i * 400: i * 400 + 400]\n",
    "    x_train = news_fivecross[i * 400 + 400: i * 400 + 2000]\n",
    "    y_train = tar_fivecross[i * 400 + 400: i * 400 + 2000]\n",
    "\n",
    "    train_vec = vector.fit_transform(x_train)\n",
    "    test_vec = vector.transform(x_test)\n",
    "\n",
    "    svc = LinearSVC()\n",
    "    svc.fit(train_vec, y_train)\n",
    "    res = svc.predict(test_vec)\n",
    "    res_fivecross.append(f1_score(y_test, res, average='macro'))\n",
    "    \n",
    "# print(res_fivecross)\n",
    "\n",
    "# print(\"final result: {:f}\".format(sum(five_cross_results) / 5))\n",
    "\n",
    "y = svc.predict(test_vec)\n",
    "print(classification_report(y_test, y, target_names=news_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}